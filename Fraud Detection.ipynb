{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Fraud Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monanjo123/Fraud-Detection/blob/master/Fraud%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMYcRbj2PN2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0d70b530-3402-4b85-fc18-b8749d1ead2a"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import numpy as np\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import copy\n",
        "from pandas import concat, DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals import joblib\n",
        "import zipfile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH89fW4AvE3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "6f663afc-3f65-4671-9ad9-2e41d3e1aaa3"
      },
      "source": [
        "data = [[187865,363],[4910,1741]]\n",
        "\n",
        "print(data)\n",
        "sns.heatmap(data, annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[187865, 363], [4910, 1741]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD8CAYAAACFK0QrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEDJXEQkAErmIiIB+F+bs4ChzTcZVQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi5_2zFEPfGr",
        "colab_type": "code",
        "outputId": "ce34b182-2896-4494-e7eb-681c6b84042a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZETb9D_uPN2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip dataset zip file\n",
        "local_zip = '/content/drive/My Drive/Machine Learning/datasets/ieee-fraud-detection.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/drive/My Drive/Machine Learning/datasets/iiee-fraud-detection')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hycr-W00PN2w",
        "colab_type": "text"
      },
      "source": [
        "# Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bozTfVauPN2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path ='/content/drive/My Drive/Machine Learning/datasets/iiee-fraud-detection'\n",
        "train_transaction = pd.read_csv('{}/train_transaction.csv'.format(data_path), low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeQs9guxRNPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    numv = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2 \n",
        "    for col in df.columns:\n",
        "        vt = df[col].dtypes\n",
        "        if vt in numv:\n",
        "            max_c = df[col].max()\n",
        "            min_c = df[col].min()\n",
        "            if str(vt)[:3] == 'int':\n",
        "                if min_c > np.iinfo(np.int8).min and max_c < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif min_c > np.iinfo(np.int16).min and max_c < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif min_c > np.iinfo(np.int32).min and max_c < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif min_c > np.iinfo(np.int64).min and max_c < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if min_c > np.finfo(np.float16).min and max_c < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif min_c > np.finfo(np.float32).min and max_c < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                elif min_c > np.finfo(np.float64).min and max_c < np.finfo(np.float64).max:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Ue1JinhxO6",
        "colab_type": "code",
        "outputId": "94f30b45-f1f7-42d6-ca66-45486561de3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_transaction = reduce_mem_usage(train_transaction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 542.35 Mb (69.4% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg6gOeF3kBVl",
        "colab_type": "code",
        "outputId": "f799328b-d52e-4c4f-d9e3-cccbd854f17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "train_transaction.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZIAU8sgkEUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete Useless Columns\n",
        "miss_data = pd.isnull(train_transaction).sum().sort_values(ascending=False)\n",
        "miss_per = (miss_data/len(train_transaction))*100\n",
        "missing_data = pd.concat(objs = [miss_data, miss_per], keys = ['Columns','Missing values percentage'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7qiWYQwkLm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delnullcol(dt):\n",
        "    nullcol = [col for col in dt.columns if dt[col].isnull().sum()/dt.shape[0] >= 0.9]\n",
        "    return nullcol"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6XExeJLkRHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rep_vals = [col for col in train_transaction.columns if train_transaction[col].value_counts(dropna = False, normalize = True).values[0] >= 0.9]\n",
        "cols=[]\n",
        "for col in rep_vals:\n",
        "    cols.append(train_transaction[col].value_counts(dropna = False).values[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1hp5LihkSdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def repcols(dt):\n",
        "    rep_vals = [col for col in dt.columns if dt[col].value_counts(dropna = False, normalize = True).values[0] >= 0.9]\n",
        "    return rep_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33hKFgN4kVYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def useless_cols(dt, exep):\n",
        "    null_cols = delnullcol(dt)\n",
        "    print(\"More than 90% null: \" + str(len(null_cols)))\n",
        "    too_many_repeated = repcols(dt)\n",
        "    print(\"More than 90% repeated value: \" + str(len(too_many_repeated)))\n",
        "    cols_to_drop = list(set(null_cols + too_many_repeated))\n",
        "    cols_to_drop.remove(exep)\n",
        "    return cols_to_drop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1DVeS_ekXzQ",
        "colab_type": "code",
        "outputId": "8670e530-6550-4379-f0fc-5ec2b18128af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cols_to_drop = useless_cols(train_transaction, 'isFraud')\n",
        "train_transaction = train_transaction.drop(cols_to_drop, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "More than 90% null: 2\n",
            "More than 90% repeated value: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG_p55BwkaEz",
        "colab_type": "code",
        "outputId": "d7a53ce4-0c18-4a6d-dc3e-88dc8e49d847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "X_cols = train_transaction.columns[4:]\n",
        "y_cols = 'isFraud'\n",
        "X = train_transaction[X_cols]\n",
        "y = train_transaction[y_cols]\n",
        "# print(X.dtypes)\n",
        "# Categorical boolean mask\n",
        "categorical_features = X.dtypes==object\n",
        "# filter categorical columns using mask and turn it into a list\n",
        "categorical = X.columns[categorical_features].tolist()\n",
        "print(categorical)\n",
        "numerical_features = ~categorical_features\n",
        "numerical = X.columns[numerical_features].tolist()\n",
        "print(numerical)\n",
        "X[categorical] = X[categorical].fillna('NA')\n",
        "X[numerical] = X[numerical].fillna(-1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
            "['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294', 'V302', 'V303', 'V304', 'V306', 'V307', 'V308', 'V310', 'V312', 'V313', 'V314', 'V315', 'V317', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3391: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self[k1] = value[k2]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7DtdOAJ-bJ6",
        "colab_type": "code",
        "outputId": "5f18f1df-e235-4831-84a8-519bb36d6c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# save dataset\n",
        "joblib.dump(X, '{}/datasetX.joblib'.format(data_path))\n",
        "joblib.dump(y, '{}/datasetY.joblib'.format(data_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Machine Learning/datasets/iiee-fraud-detection/datasetY.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoiiL1h7-Dr8",
        "colab_type": "code",
        "outputId": "74342b3d-0018-4927-d1f6-febc9189b9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "preprocess = make_column_transformer(\n",
        "    (numerical, StandardScaler()),\n",
        "    (categorical, OneHotEncoder())\n",
        ")\n",
        "new_X = preprocess.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:778: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
            "  warnings.warn(message, DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o7XF8045DLV",
        "colab_type": "code",
        "outputId": "18493331-c9d1-4b96-f309-3a9088fef3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(y.values)\n",
        "print(new_X.shape)\n",
        "print(y.values.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_X, y.values, test_size=0.33)\n",
        "del new_X, X, y\n",
        "print(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "(590540, 484)\n",
            "(590540,)\n",
            "[[ 0.30345133  1.21616345 -0.20160017 ...  0.          1.\n",
            "   0.        ]\n",
            " [-0.68733331 -0.92808513 -0.20160017 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.70760699  1.38819485 -0.20160017 ...  0.          0.\n",
            "   1.        ]\n",
            " ...\n",
            " [-0.3221141   0.73078913 -0.20160017 ...  1.          0.\n",
            "   0.        ]\n",
            " [-0.00871928  1.21616345 -0.20160017 ...  0.          0.\n",
            "   1.        ]\n",
            " [-1.06030578 -1.51176311 -0.20160017 ...  0.          0.\n",
            "   1.        ]] [0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip67Yvm-PN3B",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7SIkONxPN3C",
        "colab_type": "code",
        "outputId": "b2cd2d4e-0089-44f3-ddce-134a7a4c725d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "classifier_lr = LogisticRegression(random_state=0)\n",
        "classifier_lr.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMnJaD75mLqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier_lr.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPtzLtOqqruw",
        "colab_type": "code",
        "outputId": "d450b74f-bac3-48a7-f644-2f9cbc5be8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model_performance('Logistic Regression', y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name: Logistic Regression\n",
            "[[187865    363]\n",
            " [  4910   1741]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Ro4D7xmhEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def model_performance(model_name, y_test, Y_pred):\n",
        "  print('Model name: {}'.format(model_name))\n",
        "  cm = metrics.confusion_matrix(y_test, Y_pred)\n",
        "  print(cm)\n",
        "#   print('Test accuracy (Accuracy Score): {}').format(metrics.accuracy_)\n",
        "#   score(y_test, Y_pred)\n",
        "#   print ('Test accuracy (ROC AUC Score): {}').format(metrics.roc_auc_)\n",
        "#   score(y_test, Y_pred)\n",
        "#   print('Train accuracy: {}').format(clf.score(X_train, y_train))\n",
        "#   fpr, tpr, thresholds = metrics.precision_recall_curve(y_test, Y_pred)\n",
        "#   print('Area Under the Precision-Recall Curve: {}').format(metrics.auc(fpr, tpr))\n",
        "#   false_positive_rate, true_positive_rate, thresholds = metrics.roc_\n",
        "#   curve(y_test, Y_pred)\n",
        "#   roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
        "#   plt.title('Receiver Operating Characteristic')\n",
        "#   plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
        "#   label='AUC = %0.2f'% roc_auc)\n",
        "#   plt.legend(loc='lower right')\n",
        "#   plt.plot([0,1],[0,1],'r--')\n",
        "#   plt.xlim([-0.1,1.2])\n",
        "#   plt.ylim([-0.1,1.2])\n",
        "#   plt.ylabel('True Positive Rate')\n",
        "#   plt.xlabel('False Positive Rate')\n",
        "#   plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36HFCBzQoYte",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE_1XDUyoXJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLKV4GT6oXVF",
        "colab_type": "code",
        "outputId": "f3ad3ebc-f5e7-4e0b-a522-3329c0beee6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "classifier_svm_rbf = SVC(kernel='rbf', random_state=0)\n",
        "classifier_svm_rbf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmA59VaisTg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_rbf = classifier_svm_rbf.predict(X_test)\n",
        "model_performance('SVM - RBF', y_test, y_pred_rbf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA7Pt67uoXfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_svm_linear = SVC(kernel='linear', random_state=0)\n",
        "classifier_svm_linear.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWf_-wHyshvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_linear = classifier_svm_linear.predict(X_test)\n",
        "model_performance('SVM - Linear', y_test, y_pred_linear)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwFNMhfYorGZ",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq7M4_1oqNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0SHil-nppq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "classifier_tree.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2YPOWgzsoVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_tree = classifier_svm_tree.predict(X_test)\n",
        "model_performance('Decision Tree', y_test, y_pred_tree)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}